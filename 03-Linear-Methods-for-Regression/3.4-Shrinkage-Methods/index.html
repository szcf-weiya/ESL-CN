



<!DOCTYPE html>
<html lang="zh-CN" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="The Elements of Statistical Learning(ESL) 的中文笔记、代码实现以及习题解答">
      
      
        <link rel="canonical" href="https://esl.hohoweiya.xyz/03-Linear-Methods-for-Regression/3.4-Shrinkage-Methods/index.html">
      
      
        <meta name="author" content="szcf-weiya">
      
      <!--
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
	    
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
	    
        <meta name="lang:search.language" content="en">
	    
        <meta name="lang:search.pipeline.stopwords" content="True">
	    
        <meta name="lang:search.pipeline.trimmer" content="True">
	    
        <meta name="lang:search.result.none" content="No matching documents">
	    
        <meta name="lang:search.result.one" content="1 matching document">
	    
        <meta name="lang:search.result.other" content="# matching documents">
	    
        <meta name="lang:search.tokenizer" content="[\s\-]+">
	    
	-->
      <link rel="shortcut icon" href="../../img/favicon.ico">

      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.6.0">
    
    
      
        <title>3.4 收缩的方法 - ESL CN</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.css">
      
    
    
      <script src="../../assets/javascripts/modernizr.js"></script>
    
    
          <!--rm disqus ad refer to https://www.javaer101.com/article/25891160.html-->
          <script src="../../assets/javascripts/jquery-latest.min.js"></script>
          <script>
            (function($){
              setInterval(() => {
                  $.each($('iframe'), (arr,x) => {
                      let src = $(x).attr('src');
                      if (src && src.match(/(ads-iframe)|(disqusads)/gi)) {
                          $(x).remove();
                      }
                      let title = $(x).attr('title');
                      if (!src && title == "Disqus") {
                        $(x).remove();
                      }
                  });
              }, 300);
          })(jQuery);
          </script>   
    
    
      
      
    
    
      
      <style>
      body, input {
        font-family: Optima, Segoe, “Segoe UI”, Calibri, Arial, 'Source Han Serif SC', 'Source Han Serif', 'Songti SC', 'Microsoft YaHei', sans-serif;
        }
      code, kbd, pre {
        font-family: Consolas, "Courier New", monospace;
        }
      blockquote {
        font-family: 'Palatino Linotype', 'Book Antiqua', Palatino, STKaiti, KaiTi, '楷体', SimKai, "DFKai-SB", NSimSun, serif;}
      </style>
      <!--<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">-->
      <link rel="stylesheet" href="../../css/icon.css">
      <link rel="stylesheet" href="../../css/mini-awesome/font-awesome.css">
    
    
      <link rel="stylesheet" href="../../css/misc.css">
    
    
    <script src="../../js/mathjax.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-3KDYJ30F81"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-3KDYJ30F81');
    </script>
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="black" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" id="github" width="416" height="448" viewBox="0 0 416 448"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75 19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360 304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25 2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75 1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75 0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5 46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <!--
    
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    
    -->
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
    
      <a href="#34" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://esl.hohoweiya.xyz" title="ESL CN" class="md-header-nav__button md-logo">
          
            <img src="../../img/logo_white_24x24.svg" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                ESL CN
              </span>
              <span class="md-header-nav__topic">
                3.4 收缩的方法
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <!--
        
          
        
        -->
        <!-- <div style="padding-top:0.4rem;padding-bottom:0.4rem;width:15rem;height:4rem;">
          <iframe src="https://github.com/sponsors/szcf-weiya/button" title="Sponsor szcf-weiya" height="100%" width="100%" style="display:block;margin:auto;border:0;"></iframe>
        </div> -->
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/szcf-weiya/ESL-CN/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      szcf-weiya/ESL-CN
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../index.html" title="主页" class="md-tabs__link">
          主页
        </a>
      
    </li>
  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../01-Introduction/1.1-Introduction/index.html" title="上篇" class="md-tabs__link">
          上篇
        </a>
      
    </li>
  

  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../07-Model-Assessment-and-Selection/7.1-Introduction/index.html" title="中篇" class="md-tabs__link">
          中篇
        </a>
      
    </li>
  

  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../13-Prototype-Methods-and-Nearest-Neighbors/13.1-Introduction/index.html" title="下篇" class="md-tabs__link">
          下篇
        </a>
      
    </li>
  

  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../notes/ipynb/list/index.html" title="个人笔记" class="md-tabs__link">
          个人笔记
        </a>
      
    </li>
  

  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../tag/index.html" title="索引" class="md-tabs__link">
          索引
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <img src="../../img/logo_white_24x24.svg" width="24" height="24">
      
    </span>
    ESL CN
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/szcf-weiya/ESL-CN/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      szcf-weiya/ESL-CN
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      主页
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        主页
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../index.html" title="欢迎" class="md-nav__link">
      欢迎
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-2" type="checkbox" id="nav-1-2">
    
    <label class="md-nav__link" for="nav-1-2">
      序言
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-2">
        序言
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Preface/2016-07-20-Preface-to-the-Second-Edition/index.html" title="第二版序言" class="md-nav__link">
      第二版序言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Preface/2016-07-21-Preface-to-the-First-Edition/index.html" title="第一版序言" class="md-nav__link">
      第一版序言
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      上篇
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        上篇
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-1" type="checkbox" id="nav-2-1">
    
    <label class="md-nav__link" for="nav-2-1">
      1 简介
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-1">
        1 简介
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../01-Introduction/1.1-Introduction/index.html" title="1.1 导言" class="md-nav__link">
      1.1 导言
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2" type="checkbox" id="nav-2-2">
    
    <label class="md-nav__link" for="nav-2-2">
      2 监督学习概要
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-2">
        2 监督学习概要
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.1-Introduction/index.html" title="2.1 导言" class="md-nav__link">
      2.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.2-Variable-Types-and-Terminology/index.html" title="2.2 变量类型和术语" class="md-nav__link">
      2.2 变量类型和术语
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.3-Two-Simple-Approaches-to-Prediction/index.html" title="2.3 两种预测的简单方法" class="md-nav__link">
      2.3 两种预测的简单方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.4-Statistical-Decision-Theory/index.html" title="2.4 统计判别理论" class="md-nav__link">
      2.4 统计判别理论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.5-Local-Methods-in-High-Dimensions/index.html" title="2.5 高维问题的局部方法" class="md-nav__link">
      2.5 高维问题的局部方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.6-Statistical-Models-Supervised-Learning-and-Function-Approximation/index.html" title="2.6 统计模型，监督学习和函数逼近" class="md-nav__link">
      2.6 统计模型，监督学习和函数逼近
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.7-Structured-Regression-Models/index.html" title="2.7 结构化的回归模型" class="md-nav__link">
      2.7 结构化的回归模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.8-Classes-of-Restricted-Estimators/index.html" title="2.8 限制性估计的种类" class="md-nav__link">
      2.8 限制性估计的种类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/2.9-Model-Selection-and-the-Bias-Variance-Tradeoff/index.html" title="2.9 模型选择和偏差-方差的权衡" class="md-nav__link">
      2.9 模型选择和偏差-方差的权衡
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../02-Overview-of-Supervised-Learning/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-3" type="checkbox" id="nav-2-3" checked>
    
    <label class="md-nav__link" for="nav-2-3">
      3 回归的线性方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-3">
        3 回归的线性方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../3.1-Introduction/index.html" title="3.1 导言" class="md-nav__link">
      3.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.2-Linear-Regression-Models-and-Least-Squares/index.html" title="3.2 线性回归模型和最小二乘法" class="md-nav__link">
      3.2 线性回归模型和最小二乘法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.3-Subset-Selection/index.html" title="3.3 子集的选择" class="md-nav__link">
      3.3 子集的选择
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        3.4 收缩的方法
      </label>
    
    <a href="index.html" title="3.4 收缩的方法" class="md-nav__link md-nav__link--active">
      3.4 收缩的方法
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="岭回归" class="md-nav__link">
    岭回归
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso" title="Lasso" class="md-nav__link">
    Lasso
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso_1" title="讨论：子集的选择，岭回归，Lasso" class="md-nav__link">
    讨论：子集的选择，岭回归，Lasso
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="最小角回归" class="md-nav__link">
    最小角回归
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lar-lasso" title="LAR 和 Lasso 自由度公式" class="md-nav__link">
    LAR 和 Lasso 自由度公式
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="💬 讨论区" class="md-nav__link md-nav__link--active">
            💬 讨论区
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.5-Methods-Using-Derived-Input-Directions/index.html" title="3.5 运用派生输入方向的方法" class="md-nav__link">
      3.5 运用派生输入方向的方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.6-A-Comparison-of-the-Selection-and-Shrinkage-Methods/index.html" title="3.6 选择和收缩方法的比较" class="md-nav__link">
      3.6 选择和收缩方法的比较
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.7-Multiple-Outcome-Shrinkage-and-Selection/index.html" title="3.7 多重输出的收缩和选择" class="md-nav__link">
      3.7 多重输出的收缩和选择
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.8-More-on-the-Lasso-and-Related-Path-Algorithms/index.html" title="3.8 Lasso 和相关路径算法的补充" class="md-nav__link">
      3.8 Lasso 和相关路径算法的补充
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.9-Computational-Considerations/index.html" title="3.9 计算上的考虑" class="md-nav__link">
      3.9 计算上的考虑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-4" type="checkbox" id="nav-2-4">
    
    <label class="md-nav__link" for="nav-2-4">
      4 分类的线性方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-4">
        4 分类的线性方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../04-Linear-Methods-for-Classification/4.1-Introduction/index.html" title="4.1 导言" class="md-nav__link">
      4.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../04-Linear-Methods-for-Classification/4.2-Linear-Regression-of-an-Indicator-Matrix/index.html" title="4.2 指示矩阵的线性回归" class="md-nav__link">
      4.2 指示矩阵的线性回归
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../04-Linear-Methods-for-Classification/4.3-Linear-Discriminant-Analysis/index.html" title="4.3 线性判别分析" class="md-nav__link">
      4.3 线性判别分析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../04-Linear-Methods-for-Classification/4.4-Logistic-Regression/index.html" title="4.4 逻辑斯蒂回归" class="md-nav__link">
      4.4 逻辑斯蒂回归
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../04-Linear-Methods-for-Classification/4.5-Separating-Hyperplanes/index.html" title="4.5 分离超平面" class="md-nav__link">
      4.5 分离超平面
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../04-Linear-Methods-for-Classification/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-5" type="checkbox" id="nav-2-5">
    
    <label class="md-nav__link" for="nav-2-5">
      5 基展开和正规化
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-5">
        5 基展开和正规化
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.1-Introduction/index.html" title="5.1 导言" class="md-nav__link">
      5.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.2-Piecewise-Polynomials-and-Splines/index.html" title="5.2 分段多项式和样条" class="md-nav__link">
      5.2 分段多项式和样条
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.3-Filtering-and-Feature-Extraction/index.html" title="5.3 滤波和特征提取" class="md-nav__link">
      5.3 滤波和特征提取
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.4-Smoothing-Splines/index.html" title="5.4 光滑样条" class="md-nav__link">
      5.4 光滑样条
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.5-Automatic-Selection-of-the-Smoothing-Parameters/index.html" title="5.5 光滑参数的自动选择" class="md-nav__link">
      5.5 光滑参数的自动选择
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.6-Nonparametric-Logistic-Regression/index.html" title="5.6 非参逻辑斯蒂回归" class="md-nav__link">
      5.6 非参逻辑斯蒂回归
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.7-Multidimensional-Splines/index.html" title="5.7 多维样条" class="md-nav__link">
      5.7 多维样条
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.8-Regularization-and-Reproducing-Kernel-Hibert-Spaces/index.html" title="5.8 正则化和再生核希尔伯特空间理论" class="md-nav__link">
      5.8 正则化和再生核希尔伯特空间理论
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/5.9-Wavelet-Smoothing/index.html" title="5.9 小波光滑" class="md-nav__link">
      5.9 小波光滑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../05-Basis-Expansions-and-Regularization/Appendix-Computations-for-B-splines/index.html" title="附录-B 样条的计算" class="md-nav__link">
      附录-B 样条的计算
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-6" type="checkbox" id="nav-2-6">
    
    <label class="md-nav__link" for="nav-2-6">
      6 核光滑方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-6">
        6 核光滑方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.0-Introduction/index.html" title="6.0 导言" class="md-nav__link">
      6.0 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.1-One-Dimensional-Kernel-Smoothers/index.html" title="6.1 一维核光滑器" class="md-nav__link">
      6.1 一维核光滑器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.2-Selecting-the-Width-of-the-Kernel/index.html" title="6.2 选择核的宽度" class="md-nav__link">
      6.2 选择核的宽度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.3-Local-Regression-in-Rp/index.html" title="6.3 $\IR^p$中的局部回归" class="md-nav__link">
      6.3 $\IR^p$中的局部回归
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.4-Structured-Local-Regression-Models-in-Rp/index.html" title="6.4 $\IR^p$中的结构化局部回归模型" class="md-nav__link">
      6.4 $\IR^p$中的结构化局部回归模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.5-Local-Likelihood-and-Other-Models/index.html" title="6.5 局部似然和其他模型" class="md-nav__link">
      6.5 局部似然和其他模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.6-Kernel-Density-Estimation-and-Classification/index.html" title="6.6 核密度估计和分类" class="md-nav__link">
      6.6 核密度估计和分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.7-Radial-Basis-Functions-and-Kernels/index.html" title="6.7 径向基函数和核" class="md-nav__link">
      6.7 径向基函数和核
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.8-Mixture-Models-for-Density-Estimation-and-Classification/index.html" title="6.8 混合模型的密度估计和分类" class="md-nav__link">
      6.8 混合模型的密度估计和分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/6.9-Computational-Consoderations/index.html" title="6.9 计算上的考虑" class="md-nav__link">
      6.9 计算上的考虑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../06-Kernel-Smoothing-Methods/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      中篇
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        中篇
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-1" type="checkbox" id="nav-3-1">
    
    <label class="md-nav__link" for="nav-3-1">
      7 模型评估及选择
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-1">
        7 模型评估及选择
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.1-Introduction/index.html" title="7.1 导言" class="md-nav__link">
      7.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.2-Bias-Variance-and-Model-Complexity/index.html" title="7.2 偏差，方差和模型复杂度" class="md-nav__link">
      7.2 偏差，方差和模型复杂度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.3-The-Bias-Variance-Decomposition/index.html" title="7.3 偏差-方差分解" class="md-nav__link">
      7.3 偏差-方差分解
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.4-Optimism-of-the-Training-Error-Rate/index.html" title="7.4 测试误差率的 optimism" class="md-nav__link">
      7.4 测试误差率的 optimism
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.5-Estimates-of-In-Sample-Prediction-Error/index.html" title="7.5 样本内预测误差的估计" class="md-nav__link">
      7.5 样本内预测误差的估计
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.6-The-Effective-Number-of-Parameters/index.html" title="7.6 参数的有效个数" class="md-nav__link">
      7.6 参数的有效个数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.7-The-Bayesian-Approach-and-BIC/index.html" title="7.7 贝叶斯方法和 BIC" class="md-nav__link">
      7.7 贝叶斯方法和 BIC
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.8-Minimum-Description-Length/index.html" title="7.8 最小描述长度" class="md-nav__link">
      7.8 最小描述长度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.9-Vapnik-Chervonenkis-Dimension/index.html" title="7.9 VC 维" class="md-nav__link">
      7.9 VC 维
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.10-Cross-Validation/index.html" title="7.10 交叉验证" class="md-nav__link">
      7.10 交叉验证
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.11-Bootstrap-Methods/index.html" title="7.11 自助法" class="md-nav__link">
      7.11 自助法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/7.12-Conditional-or-Expected-Test-Error/index.html" title="7.12 条件测试误差或期望测试误差" class="md-nav__link">
      7.12 条件测试误差或期望测试误差
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../07-Model-Assessment-and-Selection/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-2" type="checkbox" id="nav-3-2">
    
    <label class="md-nav__link" for="nav-3-2">
      8 模型推断和平均
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-2">
        8 模型推断和平均
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.1-Introduction/index.html" title="8.1 导言" class="md-nav__link">
      8.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.2-The-Bootstrap-and-Maximum-Likelihood-Methods/index.html" title="8.2 自助法和最大似然法" class="md-nav__link">
      8.2 自助法和最大似然法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.3-Bayesian-Methods/index.html" title="8.3 贝叶斯方法" class="md-nav__link">
      8.3 贝叶斯方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.4-Relationship-Between-the-Bootstrap-and-Bayesian-Inference/index.html" title="8.4 自助法和贝叶斯推断之间的关系" class="md-nav__link">
      8.4 自助法和贝叶斯推断之间的关系
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.5-The-EM-Algorithm/index.html" title="8.5 EM 算法" class="md-nav__link">
      8.5 EM 算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.6-MCMC-for-Sampling-from-the-Posterior/index.html" title="8.6 从后验分布采样的 MCMC" class="md-nav__link">
      8.6 从后验分布采样的 MCMC
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.7-Bagging/index.html" title="8.7 袋装法" class="md-nav__link">
      8.7 袋装法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.8-Model-Averaging-and-Stacking/index.html" title="8.8 模型平均和堆栈" class="md-nav__link">
      8.8 模型平均和堆栈
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/8.9-Stochastic-Search/index.html" title="8.9 随机搜索" class="md-nav__link">
      8.9 随机搜索
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../08-Model-Inference-and-Averaging/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-3" type="checkbox" id="nav-3-3">
    
    <label class="md-nav__link" for="nav-3-3">
      9 增广模型，树，以及相关方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-3">
        9 增广模型，树，以及相关方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.0-Introduction/index.html" title="9.0 导言" class="md-nav__link">
      9.0 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.1-Generalized-Additive-Models/index.html" title="9.1 广义可加模型" class="md-nav__link">
      9.1 广义可加模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.2-Tree-Based-Methods/index.html" title="9.2 基于树的方法" class="md-nav__link">
      9.2 基于树的方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.3-PRIM/index.html" title="9.3 PRIM" class="md-nav__link">
      9.3 PRIM
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.4-MARS/index.html" title="9.4 多变量自适应回归样条" class="md-nav__link">
      9.4 多变量自适应回归样条
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.5-Hierarchical-Mixtures-of-Experts/index.html" title="9.5 专家的分层混合" class="md-nav__link">
      9.5 专家的分层混合
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.6-Missing-Data/index.html" title="9.6 缺失数据" class="md-nav__link">
      9.6 缺失数据
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/9.7-Computational-Considerations/index.html" title="9.7 计算上的考虑" class="md-nav__link">
      9.7 计算上的考虑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../09-Additive-Models-Trees-and-Related-Methods/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-4" type="checkbox" id="nav-3-4">
    
    <label class="md-nav__link" for="nav-3-4">
      10 增强和可加树
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-4">
        10 增强和可加树
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.1-Boosting-Methods/index.html" title="10.1 Boosting 方法" class="md-nav__link">
      10.1 Boosting 方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.2-Boosting-Fits-an-Additive-Model/index.html" title="10.2 Boosting 拟合可加模型" class="md-nav__link">
      10.2 Boosting 拟合可加模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.3-Forward-Stagewise-Additive-Modeling/index.html" title="10.3 向前逐步加性建模" class="md-nav__link">
      10.3 向前逐步加性建模
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.4-Exponential-Loss-and-AdaBoost/index.html" title="10.4 指数损失和 AdaBoost" class="md-nav__link">
      10.4 指数损失和 AdaBoost
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.5-Why-Exponential-Loss/index.html" title="10.5 为什么是指数损失" class="md-nav__link">
      10.5 为什么是指数损失
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.6-Loss-Functions-and-Robustness/index.html" title="10.6 损失函数和鲁棒性" class="md-nav__link">
      10.6 损失函数和鲁棒性
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.7-Off-the-Shelf-Procedures-for-Data-Mining/index.html" title="10.7 数据挖掘的现货方法" class="md-nav__link">
      10.7 数据挖掘的现货方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.8-Spam-Data/index.html" title="10.8 垃圾邮件的例子" class="md-nav__link">
      10.8 垃圾邮件的例子
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.9-Boosting-Trees/index.html" title="10.9 Boosting 树" class="md-nav__link">
      10.9 Boosting 树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.10-Numerical-Optimization-via-Gradient-Boosting/index.html" title="10.10 基于梯度提升的数值优化" class="md-nav__link">
      10.10 基于梯度提升的数值优化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.11-Right-Sized-Trees-for-Boosting/index.html" title="10.11 大小合适的 boosting 树" class="md-nav__link">
      10.11 大小合适的 boosting 树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.12-Regularization/index.html" title="10.12 正则化" class="md-nav__link">
      10.12 正则化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.13-Interpretation/index.html" title="10.13 解释性" class="md-nav__link">
      10.13 解释性
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/10.14-Illustrations/index.html" title="10.14 例子" class="md-nav__link">
      10.14 例子
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../10-Boosting-and-Additive-Trees/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-5" type="checkbox" id="nav-3-5">
    
    <label class="md-nav__link" for="nav-3-5">
      11 神经网络
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-5">
        11 神经网络
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/11.1-Introduction/index.html" title="11.1 导言" class="md-nav__link">
      11.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/11.2-Projection-Pursuit-Regression/index.html" title="11.2 投影寻踪回归" class="md-nav__link">
      11.2 投影寻踪回归
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/11.3-Neural-Networks/index.html" title="11.3 神经网络" class="md-nav__link">
      11.3 神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/11.4-Fitting-Neural-Networks/index.html" title="11.4 拟合神经网络" class="md-nav__link">
      11.4 拟合神经网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/11.5-Some-Issues-in-Training-Neural-Networks/index.html" title="11.5 训练神经网络的一些问题" class="md-nav__link">
      11.5 训练神经网络的一些问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/11.6-Example-of-Simulated-Data/index.html" title="11.6 模拟数据的例子" class="md-nav__link">
      11.6 模拟数据的例子
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/11.7-Example-ZIP-Code-Data/index.html" title="11.7 邮编数字的例子" class="md-nav__link">
      11.7 邮编数字的例子
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../11-Neural-Networks/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-6" type="checkbox" id="nav-3-6">
    
    <label class="md-nav__link" for="nav-3-6">
      12 支持向量机和灵活的判别方法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-6">
        12 支持向量机和灵活的判别方法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/12.1-Introduction/index.html" title="12.1 导言" class="md-nav__link">
      12.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/12.2-The-Support-Vector-Classifier/index.html" title="12.2 支持向量分类器" class="md-nav__link">
      12.2 支持向量分类器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/12.3-Support-Vector-Machines-and-Kernels/index.html" title="12.3 支持向量机和核" class="md-nav__link">
      12.3 支持向量机和核
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/12.4-Generalizing-Linear-Discriminant-Analysis/index.html" title="12.4 广义线性判别分析" class="md-nav__link">
      12.4 广义线性判别分析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/12.5-Flexible-Disciminant-Analysis/index.html" title="12.5 FDA" class="md-nav__link">
      12.5 FDA
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/12.6-Penalized-Discriminant-Analysis/index.html" title="12.6 PDA" class="md-nav__link">
      12.6 PDA
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/12.7-Mixture-Discriminant-Analysis/index.html" title="12.7 混合判别分析" class="md-nav__link">
      12.7 混合判别分析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/Computational-Considerations/index.html" title="计算上的考虑" class="md-nav__link">
      计算上的考虑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../12-Support-Vector-Machines-and-Flexible-Discriminants/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      下篇
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        下篇
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-1" type="checkbox" id="nav-4-1">
    
    <label class="md-nav__link" for="nav-4-1">
      13 原型方法和最近邻
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-1">
        13 原型方法和最近邻
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../13-Prototype-Methods-and-Nearest-Neighbors/13.1-Introduction/index.html" title="13.1 导言" class="md-nav__link">
      13.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../13-Prototype-Methods-and-Nearest-Neighbors/13.2-Prototype-Methods/index.html" title="13.2 原型方法" class="md-nav__link">
      13.2 原型方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../13-Prototype-Methods-and-Nearest-Neighbors/13.3-k-Nearest-Neighbor-Classifiers/index.html" title="13.3 k 最近邻分类器" class="md-nav__link">
      13.3 k 最近邻分类器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../13-Prototype-Methods-and-Nearest-Neighbors/13.4-Adaptive-Nearest-Neighbor-Methods/index.html" title="13.4 自适应的最近邻方法" class="md-nav__link">
      13.4 自适应的最近邻方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../13-Prototype-Methods-and-Nearest-Neighbors/13.5-Computational-Considerations/index.html" title="13.5 计算上的考虑" class="md-nav__link">
      13.5 计算上的考虑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../13-Prototype-Methods-and-Nearest-Neighbors/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-2" type="checkbox" id="nav-4-2">
    
    <label class="md-nav__link" for="nav-4-2">
      14 非监督学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-2">
        14 非监督学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.1-Introduction/index.html" title="14.1 导言" class="md-nav__link">
      14.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.2-Association-Rules/index.html" title="14.2 关联规则" class="md-nav__link">
      14.2 关联规则
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.3-Cluster-Analysis/index.html" title="14.3 聚类分析" class="md-nav__link">
      14.3 聚类分析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.4-Self-Organizing-Maps/index.html" title="14.4 自组织图" class="md-nav__link">
      14.4 自组织图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.5-Principal-Components-Curves-and-Surfaces/index.html" title="14.5 主成分、主曲线与主曲面" class="md-nav__link">
      14.5 主成分、主曲线与主曲面
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.6-Non-negative-Matrix-Factorization/index.html" title="14.6 非负矩阵分解" class="md-nav__link">
      14.6 非负矩阵分解
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.7-Independent-Component-Analysis-and-Exploratory-Projection-Pursuit/index.html" title="14.7 独立成分分析和探索投影寻踪" class="md-nav__link">
      14.7 独立成分分析和探索投影寻踪
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.8-Multidimensional-Scaling/index.html" title="14.8 多维缩放" class="md-nav__link">
      14.8 多维缩放
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.9-Nonlinear-Dimension-Reduction-and-Local-Multidimensional-Scaling/index.html" title="14.9 非线性降维和局部多维缩放" class="md-nav__link">
      14.9 非线性降维和局部多维缩放
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/14.10-The-Google-PageRank-Algorithm/index.html" title="14.10 谷歌的 PageRank 算法" class="md-nav__link">
      14.10 谷歌的 PageRank 算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../14-Unsupervised-Learning/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3" type="checkbox" id="nav-4-3">
    
    <label class="md-nav__link" for="nav-4-3">
      15 随机森林
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-3">
        15 随机森林
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../15-Random-Forests/15.1-Introduction/index.html" title="15.1 导言" class="md-nav__link">
      15.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../15-Random-Forests/15.2-Definition-of-Random-Forests/index.html" title="15.2 随机森林的定义" class="md-nav__link">
      15.2 随机森林的定义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../15-Random-Forests/15.3-Details-of-Random-Forests/index.html" title="15.3 随机森林的细节" class="md-nav__link">
      15.3 随机森林的细节
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../15-Random-Forests/15.4-Analysis-of-Random-Forests/index.html" title="15.4 随机森林的分析" class="md-nav__link">
      15.4 随机森林的分析
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../15-Random-Forests/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-4" type="checkbox" id="nav-4-4">
    
    <label class="md-nav__link" for="nav-4-4">
      16 集成学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-4">
        16 集成学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../16-Ensemble-Learning/16.1-Introduction/index.html" title="16.1 导言" class="md-nav__link">
      16.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../16-Ensemble-Learning/16.2-Boosting-and-Regularization-Paths/index.html" title="16.2 增强和正则路径" class="md-nav__link">
      16.2 增强和正则路径
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../16-Ensemble-Learning/16.3-Learning-Ensembles/index.html" title="16.3 学习集成" class="md-nav__link">
      16.3 学习集成
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../16-Ensemble-Learning/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5" type="checkbox" id="nav-4-5">
    
    <label class="md-nav__link" for="nav-4-5">
      17 无向图模型
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-5">
        17 无向图模型
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../17-Undirected-Graphical-Models/17.1-Introduction/index.html" title="17.1 导言" class="md-nav__link">
      17.1 导言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../17-Undirected-Graphical-Models/17.2-Markov-Graphs-and-Their-Properties/index.html" title="17.2 马尔科夫图及其性质" class="md-nav__link">
      17.2 马尔科夫图及其性质
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../17-Undirected-Graphical-Models/17.3-Undirected-Graphical-Models-for-Continuous-Variables/index.html" title="17.3 连续变量的无向图模型" class="md-nav__link">
      17.3 连续变量的无向图模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../17-Undirected-Graphical-Models/17.4-Undirected-Graphical-Models-for-Discrete-Variables/index.html" title="17.4 离散变量的无向图模型" class="md-nav__link">
      17.4 离散变量的无向图模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../17-Undirected-Graphical-Models/Bibliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-6" type="checkbox" id="nav-4-6">
    
    <label class="md-nav__link" for="nav-4-6">
      18 高维问题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-6">
        18 高维问题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/18.1-When-p-is-Much-Bigger-than-N/index.html" title="18.1 当 p 大于 N" class="md-nav__link">
      18.1 当 p 大于 N
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/18.2-Diagonal-Linear-Discriminant-Analysis-and-Nearest-Shrunken-Centroids/index.html" title="18.2 对角线性判别分析和最近收缩重心" class="md-nav__link">
      18.2 对角线性判别分析和最近收缩重心
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/18.3-Linear-Classifiers-with-Quadratic-Regularization/index.html" title="18.3 二次正则的线性分类器" class="md-nav__link">
      18.3 二次正则的线性分类器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/18.4-Linear-Classifiers-with-L1-Regularization/index.html" title="18.4 一次正则的线性分类器" class="md-nav__link">
      18.4 一次正则的线性分类器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/18.5-Classification-When-Features-are-Unavailable/index.html" title="18.5 当特征不可用时的分类" class="md-nav__link">
      18.5 当特征不可用时的分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/18.6-High-Dimensional-Regression/index.html" title="18.6 有监督的主成分" class="md-nav__link">
      18.6 有监督的主成分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/18.7-Feature-Assessment-and-the-Multiple-Testing-Problem/index.html" title="18.7 特征评估和多重检验问题" class="md-nav__link">
      18.7 特征评估和多重检验问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../18-High-Dimensional-Problems/Bioliographic-Notes/index.html" title="文献笔记" class="md-nav__link">
      文献笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      个人笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        个人笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1">
    
    <label class="md-nav__link" for="nav-5-1">
      笔记列表
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        笔记列表
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/ipynb/list/index.html" title="列表" class="md-nav__link">
      列表
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-2" type="checkbox" id="nav-5-2">
    
    <label class="md-nav__link" for="nav-5-2">
      实验重现
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-2">
        实验重现
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/linear-reg/sim-3-18/index.html" title="模拟 Fig. 3.18" class="md-nav__link">
      模拟 Fig. 3.18
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/LDA/sim-4-3/index.html" title="模拟 Fig. 4.3" class="md-nav__link">
      模拟 Fig. 4.3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/LDA/sim-4-5/index.html" title="模拟 Fig. 4.5" class="md-nav__link">
      模拟 Fig. 4.5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/spline/sim-5-9/index.html" title="模拟 Fig. 5.9" class="md-nav__link">
      模拟 Fig. 5.9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/ModelSelection/sim7_3/index.html" title="模拟 Fig. 7.3" class="md-nav__link">
      模拟 Fig. 7.3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/ModelSelection/sim7_7/index.html" title="模拟 Fig. 7.7" class="md-nav__link">
      模拟 Fig. 7.7
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/ModelSelection/sim7_9/index.html" title="模拟 Fig. 7.9" class="md-nav__link">
      模拟 Fig. 7.9
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Prototype/sim13_5/index.html" title="模拟 Fig. 13.5" class="md-nav__link">
      模拟 Fig. 13.5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/ICA/sim14_42/index.html" title="模拟 Fig. 14.42" class="md-nav__link">
      模拟 Fig. 14.42
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/boosting/sim-eq-10-2/index.html" title="模拟 Eq. 10.2" class="md-nav__link">
      模拟 Eq. 10.2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/SVM/skin-of-the-orange/index.html" title="模拟 Tab. 12.2" class="md-nav__link">
      模拟 Tab. 12.2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/tree/sim-9-7/index.html" title="模拟 Fig. 9.7" class="md-nav__link">
      模拟 Fig. 9.7
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Graph/alg-17-1/index.html" title="算法 Alg. 17.1" class="md-nav__link">
      算法 Alg. 17.1
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-3" type="checkbox" id="nav-5-3">
    
    <label class="md-nav__link" for="nav-5-3">
      比较总结
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-3">
        比较总结
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/Mixture-Gaussian/index.html" title="估计高斯混合模型参数的三种方式" class="md-nav__link">
      估计高斯混合模型参数的三种方式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/SVM/e1071/index.html" title="SVM 处理线性和非线性类别边界" class="md-nav__link">
      SVM 处理线性和非线性类别边界
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/boosting/summary-loss-function/index.html" title="损失函数的梯度总结及 Julia 实现" class="md-nav__link">
      损失函数的梯度总结及 Julia 实现
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/tree/various-classification-methods/index.html" title="R 语言中的多种决策树算法实现" class="md-nav__link">
      R 语言中的多种决策树算法实现
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/missing-data/missing-data/index.html" title="R 语言处理缺失数据" class="md-nav__link">
      R 语言处理缺失数据
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../notes/BS/bs/index.html" title="B 样条在 R, Python, Cpp 中的实现" class="md-nav__link">
      B 样条在 R, Python, Cpp 中的实现
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      索引
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        索引
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../tag/index.html" title="关键词" class="md-nav__link">
      关键词
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="岭回归" class="md-nav__link">
    岭回归
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso" title="Lasso" class="md-nav__link">
    Lasso
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lasso_1" title="讨论：子集的选择，岭回归，Lasso" class="md-nav__link">
    讨论：子集的选择，岭回归，Lasso
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="最小角回归" class="md-nav__link">
    最小角回归
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lar-lasso" title="LAR 和 Lasso 自由度公式" class="md-nav__link">
    LAR 和 Lasso 自由度公式
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="💬 讨论区" class="md-nav__link md-nav__link--active">
            💬 讨论区
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/szcf-weiya/ESL-CN/edit/master/docs/03-Linear-Methods-for-Regression/3.4-Shrinkage-Methods.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="34">3.4 收缩的方法<a class="headerlink" href="#34" title="Permanent link">&para;</a></h1>
<table>
<thead>
<tr>
<th>原文</th>
<th><a href="https://esl.hohoweiya.xyz/book/The%20Elements%20of%20Statistical%20Learning.pdf#page=80">The Elements of Statistical Learning</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>翻译</td>
<td>szcf-weiya</td>
</tr>
<tr>
<td>发布</td>
<td>2016-09-30</td>
</tr>
<tr>
<td>更新</td>
<td>2018-03-22, 2018-03-23, 2018-03-24</td>
</tr>
<tr>
<td>状态</td>
<td>Done</td>
</tr>
</tbody>
</table>
<p>通过保留一部分预测变量而丢弃剩余的变量，<strong>子集选择 (subset selection)</strong> 可得到一个可解释的、预测误差可能比全模型低的模型．然而，因为这是一个离散的过程（变量不是保留就是丢弃），所以经常表现为高方差，因此不会降低全模型的预测误差．而<strong>收缩方法 (shrinkage methods)</strong> 更加连续，因此不会受 <strong>高易变性 (high variability)</strong> 太大的影响．</p>
<h2 id="_1">岭回归<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p><strong>岭回归 (Ridge regression)</strong> 根据回归系数的大小加上惩罚因子对它们进行收缩．岭回归的系数使得带惩罚的残差平方和最小</p>
<p>
<script type="math/tex; mode=display">
\hat{\beta}^{ridge}=\underset{\beta}{\arg\min}\Big\{\sum\limits_{i=1}^N(y_i-\beta_0-\sum\limits_{j=1}^px_{ij}\beta_j)^2+\lambda\sum\limits_{j=1}^p\beta_j^2\Big\}\tag{3.41}\label{3.41}
</script>
</p>
<p>这里$\lambda\ge 0 $是控制收缩程度的参数：$\lambda$值越大，收缩的程度越大．每个系数都向零收缩．<!--系数向零收缩（并且彼此收缩到一起）．-->通过参数的平方和来惩罚的想法也用在了神经网络，也被称作 <strong>权重衰减 (weight decay)</strong>（<a href="../../11-Neural-Networks/11.3-Neural-Networks/index.html">第 11 章</a>）．</p>
<p>岭回归问题可以等价地写成</p>
<p>
<script type="math/tex; mode=display">
\begin{align*}
\hat{\beta}^{ridge}&=\underset{\beta}{\arg\min}\sum\limits_{i=1}^N(y_i-\beta_0-\sum\limits_{j=1}^px_{ij}\beta_j)^2\\\
& \text{subject to }\sum\limits_{j=1}^p\beta_j^2 \le t
\end{align*}
\tag{3.42}\label{3.42}
</script>
</p>
<p>上式用参数显式表达了对回归参数大小的约束．</p>
<div class="admonition note">
<p class="admonition-title">weiya 注：</p>
<p>式 \eqref{3.41} 其实是对式 \eqref{3.42} 应用 Lagrange 乘子法得到的．</p>
</div>
<p>\eqref{3.41} 中的 $\lambda$ 和 \eqref{3.42} 中的 $t$ 存在一一对应．当在线性回归模型中有许多相关变量，它们的系数可能很难确定且有高方差．某个变量的较大的正系数可以与相关性强的变量的差不多大的负系数相互抵消．通过对系数加入大小限制，如 \eqref{3.42}，这个问题能得以减轻．</p>
<div class="admonition note">
<p class="admonition-title">weiya 注：</p>
<p>这里说的是，在没有对参数大小进行限制前，会存在一对相关性强的变量，它们系数取值符号相反，但绝对值差不多大，会大大增加方差，这也就是高方差的体现，但其实它们的合作用效果近似为 $0$，所以考虑引进对参数大小的惩罚．</p>
</div>
<p>对输入按比例进行缩放时，岭回归的解不相等，因此求解 \eqref{3.41} 前我们需要对输入进行标准化．另外，注意到惩罚项不包含截距 $\beta_0$．对截距的惩罚会使得过程依赖于 $\mathbf{Y}$ 的初始选择；也就是，对每个 $y_i$ 加上常数 $c$ 不是简单地导致预测值会偏离同样的量 $c$．可以证明（<a href="https://github.com/szcf-weiya/ESL-CN/issues/95">练习 3.5</a>）经过对输入进行中心化（每个 $x_{ij}$ 替换为 $x_{ij}-\bar x_j$）后，\eqref{3.41} 的解可以分成两部分．我们用 $\bar y=\frac{1}{N}\sum_1^Ny_i$ 来估计 $\beta_0$．剩余的参数利用中心化的 $x_{ij}$ 通过无截距的岭回归来估计．今后我们假设中心化已经完成，则输入矩阵 $\mathbf X$ 有 $p$（不是 $p+1$）列．</p>
<div class="admonition info">
<p class="admonition-title">weiya 注：Ex. 3.5</p>
<p>已解答，详细证明过程见 <a href="https://github.com/szcf-weiya/ESL-CN/issues/95">Issue 95: Ex. 3.5</a></p>
</div>
<p>将 \eqref{3.41} 的准则写成矩阵形式</p>
<p>
<script type="math/tex; mode=display">
\RSS(\lambda)=(\mathbf{y}-\mathbf{X}\beta)^T(\mathbf{y}-\mathbf{X}\beta)+\lambda\beta^T\beta \tag{3.43}
</script>
</p>
<p>可以简单地看出岭回归的解为</p>
<p>
<script type="math/tex; mode=display">
\hat{\beta}^{ridge}=(\mathbf{X^TX}+\lambda \mathbf{I})^{-1}\mathbf{X}^T\mathbf{y}\tag{3.44}\label{3.44}
</script>
</p>
<p>其中 $\mathbf{I}$ 为 $p\times p$ 的单位矩阵．注意到选择二次函数惩罚 $\beta^T\beta$，岭回归的解仍是 $\mathbf{y}$ 的线性函数．解在求逆之前向矩阵 $\mathbf{X^TX}$ 的对角元上加入正的常数值．即使 $\mathbf{X^TX}$ 不是满秩，这样会使得问题非奇异，而且这是第一次将岭回归引入统计学中 (Hoerl and Kennard, 1970<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>）的主要动力．传统的岭回归的描述从定义 \eqref{3.44} 开始．我们选择通过 \eqref{3.41} 和 \eqref{3.42} 来阐述，因为这两式让我们看清楚了它是怎样实现的．</p>
<p>图 3.8 展示了前列腺癌例子的岭回归系数估计，绘制成关于 $\df(\lambda)$ 的函数图象，$\df(\lambda)$ 为由惩罚 $\lambda$ 得到的 <strong>有效自由度 (effective degrees of freedom)</strong>（由式 \eqref{3.50} 中定义）．在正交输入的情形下，岭回归估计仅仅是最小二乘估计的缩小版本，也就是 $\hat{\beta}^{ridge}=\hat{\beta}/(1+\lambda)$．</p>
<p><img alt="" src="../../img/03/fig3.8.png" /></p>
<blockquote>
<p>图 3.8 当惩罚参数 $\lambda$ 不同时，前列腺癌例子岭回归的变化曲线．画出系数关于有效自由度 $\df(\lambda)$ 的曲线．垂直直线画在 $\df=5.0$ 处，这是由交叉验证选择出来的．</p>
</blockquote>
<p>当给定一个合适的先验分布，岭回归也可以从后验分布的均值或众数得到．具体地，假设 $y_i \sim N(\beta_0+x^T_i\beta,\sigma^2)$，参数 $\beta_j$ 的分布均为 $N(0,\tau^2)$，每个都相互独立．则当 $\tau^2$ 和 $\sigma^2$ 值已知时，$\beta$ 后验分布密度函数的对数值（的负数）与 \eqref{3.41} 中花括号里面的表达式成比例 <strong>(weiya 注：原文直接说与花括号的表达式相等，但应该是常数倍)</strong>，且 $\lambda=\sigma^2/\tau^2$（<a href="https://github.com/szcf-weiya/ESL-CN/issues/96">练习 3.6</a>)．因此岭回归估计是后验分布的众数；又因分布为高斯分布，则也是后验分布的均值．</p>
<div class="admonition info">
<p class="admonition-title">weiya 注：Ex. 3.6</p>
<p>将解答过程移至<a href="https://github.com/szcf-weiya/ESL-CN/issues/96">Issue 96: Ex. 3.6</a>．</p>
</div>
<!--
> **weiya注：**
>
>
> $$
> \begin{align}
> f(\beta\mid y)&=\dfrac{f(\beta, y)}{f(y)}\\\
> &=\dfrac{f(\beta,y)}{\int f(y\mid\beta)f(\beta)}\\\
> &\sim f(y\mid\beta)f(\beta)\\\
> &=Cexp\Big\{-\frac{1}{2\sigma^2}\Big[(y-\beta_0-X\beta)'(y-\beta_0-X\beta)+\frac{\sigma^2}{\tau^2}\beta'\beta\Big]\Big\}
> \end{align}
> $$
>
> $\color{red} 疑问：C是多少？$
> 通过
> $$
> \int Cf(\beta\mid y)d\beta=1
> $$
> 来确定C
> $$
> C = \dfrac{1}{(2\pi)^N\tau\sigma \Vert XX'\Vert^{1/2}}
> $$
>
>
> 取对数，有
> $$
> log(f(\beta\mid y))=-\frac{1}{2\sigma^2}[(y-\beta_0-X\beta)'(y-\beta_0-X\beta)+\frac{\sigma^2}{\tau^2}\beta'\beta]+log(C)
> $$
>
> 则$\lambda=\frac{\sigma^2}{\tau^2}$,且岭回归估计是后验分布的众数．
-->

<p>中心化输入矩阵 $\mathbf{X}$ 的 <strong>奇异值分解 (SVD)</strong> 让我们进一步了解了岭回归的本质．这个分解在许多统计方法分析中非常有用．$N\times p$ 阶矩阵 $\mathbf{X}$ 的 SVD 分解有如下形式</p>
<p>
<script type="math/tex; mode=display">
\mathbf{X=UDV^T}\tag{3.45}\label{3.45}
</script>
</p>
<p>这里 $\mathbf{U}$ 和 $\mathbf{V}$ 分别是 $N\times p$ 和 $p\times p$ 的正交矩阵，$\mathbf{U}$的列张成 $X$ 的列空间，$\mathbf{V}$ 的列张成 $X$ 的行空间．$\mathbf{D}$ 为 $p\times p$ 的对角矩阵，对角元 $d_1\ge d_2 \ge \cdots \ge d_p \ge 0$ 称作 $\mathbf{X}$ 的奇异值．如果一个或多个 $d_j=0$，则 $\mathbf{X}$ 为奇异的．</p>
<div class="admonition note">
<p class="admonition-title">weiya 注: 奇异值分解（张贤达的《矩阵分析与应用》）</p>
<p>奇异值分解最早由 Beltrami 在 1873 年对实正方矩阵提出来的．Beltrami 从双线性函数
<script type="math/tex; mode=display">
f(x,y)=x^TAy,\qquad A\in \IR^{n\times m}
</script>
出发，通过引入线性变换
<script type="math/tex; mode=display">
x=U\xi,\qquad y=V\eta
</script>
将双线性函数变为
<script type="math/tex; mode=display">
f(x,y)=\xi^TS\eta
</script>
其中
<script type="math/tex; mode=display">
S=U^TAV\,.
</script>
若选择 $U$ 和 $V$ 为正交矩阵，则他们的选择各存在 $n^2-n$ 个自由度．他提出利用这些自由度使矩阵 $S$ 的非对角元为0，即矩阵$S=\Sigma=\diag(\sigma_1,\sigma_2,\ldots,\sigma_n)$为对角矩阵．则
<script type="math/tex; mode=display">
A=U\Sigma V^T
</script>
这是 Beltrami 于 1873 年得到的实正方矩阵的奇异值分解．后来，Autonne 于 1902 年把奇异值分解推广到复正方矩阵；Eckart 与 Young 于 1939 年又进一步把它推广到一般的长方形矩阵．因此，现在常将任意复长方矩阵奇异值分解定理称为 Autonee-Eckart-Young 定理，即</p>
<p>令 $A\in \IR^{m\times n}$(或$C^{m\times n}$),则存在正交（或酉）矩阵 $U\in \IR^{m\times m}$(或 $C^{m\times m}$)和 $V\in \IR^{n\times n}$(或$C^{n\times n}$)使得
<script type="math/tex; mode=display">
A=U\Sigma V^T(or\quad U\Sigma V^H)
</script>
式中
<script type="math/tex; mode=display">
\Sigma=
\left[
\begin{array}{cc}
\Sigma_1&O\\
O&O
\end{array}
\right]
</script>
且$\Sigma_1=diag(\sigma_1,\sigma_2,\ldots,\sigma_r)$,其对角元素按照顺序
<script type="math/tex; mode=display">
\sigma_1\gt \sigma_2\cdots\ge\sigma_r>0,\qquad r=rank(A)
</script>
排列.</p>
<p>下图（来自<a href="https://en.wikipedia.org/wiki/Singular_value_decomposition#/media/File:Reduced_Singular_Value_Decompositions.svg">维基百科</a>）形象地展示了 SVD 的四种不同形式，</p>
<p><img alt="" src="../../img/03/Reduced_Singular_Value_Decompositions.svg.png" /></p>
<ul>
<li>Full SVD:</li>
<li>Thin SVD: 只保留 $U$ 中对应 $V^T$ 中行向量的 $n$ 个列向量</li>
<li>Compact SVD: 去掉零奇异值对应的行和列</li>
<li>Truncated SVD: 保留前 $t$ 个最大奇异值对应的行和列</li>
</ul>
</div>
<p>利用奇异值分解，通过简化我们可以把最小二乘拟合向量写成</p>
<p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{X}\hat{\beta}^{ls}&=\mathbf{X(X^TX)^{-1}X^Ty}\notag\\
&=\mathbf{UU^Ty}\tag{3.46}
\end{align}
</script>
</p>
<p>注意到 $\mathbf{U}^T\mathbf y$ 是 $\mathbf{y}$ 正交基 $\mathbf{U}$ 下的坐标．同时注意其与 \eqref{3.33} 的相似性；</p>
<div class="admonition note">
<p class="admonition-title">weiya 注：Recall</p>
<p>
<script type="math/tex; mode=display">
\begin{align}
\hat{\beta}&=\mathbf{R^{-1}Q^Ty}\tag{3.32}\label{3.32} \\
\hat{\mathbf{y}}&=\mathbf{QQ^Ty}\tag{3.33}\label{3.33}
\end{align}
</script>
</p>
</div>
<p>$\mathbf{Q}$ 和 $\mathbf{U}$ 是 $\mathbf{X}$ 列空间的两个不同的正交基（<a href="https://github.com/szcf-weiya/ESL-CN/issues/97">练习 3.8</a>）．</p>
<div class="admonition info">
<p class="admonition-title">weiya 注：Ex. 3.8</p>
<p>已解答，具体证明过程见 <a href="https://github.com/szcf-weiya/ESL-CN/issues/97">Issue 97: Ex. 3.8</a></p>
</div>
<p>现在岭回归的解为</p>
<p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{X}\hat{\beta}^{ridge}&=\mathbf{X}(\mathbf{X^TX}+\lambda \mathbf{I})^{-1}\mathbf{X^Ty}\notag\\
&= \mathbf{UD}(\mathbf{D^2}+\lambda \mathbf{I})^{-1}\mathbf{DU^Ty}\notag\\
&= \sum\limits_{j=1}^p\mathbf{u}_j\dfrac{d_j^2}{d_j^2+\lambda}\mathbf{u_j^Ty}\tag{3.47}
\end{align}
</script>
</p>
<p>其中 $\mathbf{u}_j$ 是 $\mathbf{U}$ 的列向量．注意到因为 $\lambda \ge 0$，我们有 $d_j^2/(d^2_j+\lambda)\le 1$．类似线性回归，岭回归计算 $\mathbf{y}$ 关于正规基 $\mathbf{U}$ 的坐标．通过因子 $d^2_j/(d^2_j+\lambda)$ 来收缩这些坐标．这意味着更小的 $d_j^2$ 会在更大程度上收缩基向量的坐标．</p>
<p>$d_j^2$ 值小意味着什么？中心化后的矩阵 $\mathbf{X}$ 的奇异值分解是表示 $\mathbf{X}$ 中主成分变量的另一种方式．样本协方差矩阵为 $\mathbf{S=X^TX}/N$<!--$\mathbf{S={\color{red} E((X-EX)^T(X-EX))=}X^TX}/N$-->，并且从 \eqref{3.45} 式我们得到</p>
<p>
<script type="math/tex; mode=display">
\mathbf{X^T X = VD^2V^T} \tag{3.48}
</script>
</p>
<p>上式是 $\mathbf{X^TX}$（当忽略因子 $N$ 时，也是 $S$）的 <strong>特征值分解 (eigen decomposition)</strong>．特征向量 $v_j$（$\mathbf{V}$ 的列向量）也称作 $\mathbf{X}$ 的 <strong>主成分 (principal components)</strong>（或 Karhunen-Loeve）方向．第一主成分方向 $v_1$ 有下面性质：$\mathbf{z}_1=\mathbf{X}v_1$ 在所有 $\mathbf{X}$ 列的标准化线性组合中有最大的样本方差．样本方差很容易看出来是</p>
<p>
<script type="math/tex; mode=display">
\Var(\mathbf{z}_1)=\Var(\mathbf{X}v_1)=\dfrac{d_1^2}{N}\tag{3.49}
</script>
</p>
<p>事实上 $\mathbf{z}_1=\mathbf{X}v_1=\mathbf{u}_1d_1$．导出变量 $\mathbf{z_1}$ 称作 $\mathbf{X}$ 的第一主成分，因此 $\mathbf{u_1}$ 是标准化的第一主成分．后面的主成分 $z_j$ 在与前一个保持正交的前提下有最大的方差 $d_j^2/N$．所以，最后一个主成分有最小的方差．因此越小的奇异值 $d_j$ 对应 $\mathbf{X}$ 列空间中方差越小的方向，并且岭回归在这些方向上收缩得最厉害．</p>
<p>图 3.9 展示了两个维度下部分数据点的主成分．如果我们考虑在这个区域（$Y$ 轴垂直纸面）内拟合线性曲面，数据的结构形态使得确定梯度时长方向会比短方向更精确．岭回归防止在短方向上估计梯度可能存在的高方差．隐含的假设是响应变量往往在高方差的输入方向上变化．这往往是个合理的假设，因为我们所研究的预测变量随响应变量变化而变化，而不需要保持不变．</p>
<p><img alt="" src="../../img/03/fig3.9.png" /></p>
<blockquote>
<p>图 3.9 部分输入数据点的主成分．最大主成分是使得投影数据方差最大的方向，最小主成分是使得方差最小的方向．岭回归将 $\mathbf{y}$ 投射到这些成分上，然后对低方差成分的系数比高方差收缩得更厉害．</p>
</blockquote>
<p>在图 3.7 中我们已经画了预测误差估计值关于 $\df(\lambda)$ 的曲线</p>
<p>
<script type="math/tex; mode=display">
\begin{align}
\df(\lambda)&=\tr[\mathbf{X}(\mathbf{X^TX}+\lambda\mathbf{I})^{-1}\mathbf{X}^T]\notag\\
&=\tr(\mathbf{H}_{\lambda})\notag\\
&=\sum\limits_{j=1}^p\dfrac{d_j^2}{d_j^2+\lambda}\tag{3.50}\label{3.50}
\end{align}
</script>
</p>
<p>上面 $\lambda$ 的单调递减函数是岭回归拟合的 <strong>有效自由度 (effective degrees of freedom)</strong>．通常在含 $p$ 个变量的线性回归拟合中，拟合的自由度为 $p$，也就是无约束参数的个数．这里想法是尽管岭回归拟合中所有的 $p$ 个系数都不为 0，但是它们在由 $\lambda$ 控制的约束下拟合．注意到当 $\lambda=0$（没有正则化）时 $\df(\lambda)=p$，并且当 $\lambda\rightarrow \infty$ 时 $df(\lambda)\rightarrow 0$．当然总是对于截距总有一个额外的自由度，事先 (apriori) 已经去掉了．这个定义将在 <a href="#_2">3.4.4 节</a>和 <a href="../../07-Model-Assessment-and-Selection/7.4-Optimism-of-the-Training-Error-Rate/index.html">7.4-7.6 节</a>中详细介绍．图 3.7 中最小值在 $\df(\lambda)=5.0$ 处．表 3.3 表明岭回归将全最小二乘估计的测试误差降低了一小部分．</p>
<h2 id="lasso">Lasso<a class="headerlink" href="#lasso" title="Permanent link">&para;</a></h2>
<div class="admonition note">
<p class="admonition-title">weiya 注：</p>
<p>lasso 是 “Least absolute shrinkage and seleetion operator” 的首字母缩写．</p>
</div>
<p>lasso 像岭回归一样是个收缩方法，有微妙但很重要的区别．lasso 估计定义如下</p>
<p>
<script type="math/tex; mode=display">
\begin{align}
\hat{\beta}^{lasso}&=\underset{\beta}{\arg\min}\sum\limits_{i=1}^N(y_i-\beta_0-\sum\limits_{j=1}^px_{ij}\beta_j)^2\notag\\
&\text{subject to }\sum\limits_{j=1}^p\vert\beta_j\vert\le t \tag{3.51}
\end{align}
</script>
</p>
<p>正如在岭回归中一样，我们可以通过标准化预测变量来对常数 $\beta_0$ 再参量化；$\hat{\beta}_0$ 的解为 $\bar{y}$，并且后面我们拟合无截距的模型（<a href="https://github.com/szcf-weiya/ESL-CN/issues/95">练习 3.5</a>）．</p>
<div class="admonition info">
<p class="admonition-title">weiya 注：Ex. 3.5</p>
<p>已解答，详细证明过程见 <a href="https://github.com/szcf-weiya/ESL-CN/issues/95">Issue 95: Ex. 3.5</a></p>
</div>
<p>在信号处理中，lasso 也被称作 basis pursuit (Chen et al., 1998<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>)</p>
<p>我们也可以把 lasso 问题等价地写成 <strong>拉格朗日形式 (Lagrangian form)</strong></p>
<p>
<script type="math/tex; mode=display">
\hat{\beta}^{lasso}=\underset{\beta}{\arg\min}\Big\{\sum\limits_{i=1}^N(y_i-\beta_0-\sum\limits_{j=1}^px_{ij}\beta_j)^2+\lambda\sum\limits_{j=1}^p\vert\beta_j\vert\Big\}\tag{3.52}\label{3.52}
</script>
</p>
<p>注意到这与岭回归问题 \eqref{3.42} 或 \eqref{3.41} 的相似性：$L_2$ 的岭回归惩罚 $\sum_1^p\beta^2_j$ 替换为 $L_1$ 的 lasso 惩罚$\sum_1^p\vert\beta_j\vert$．后一约束使得解在 $y_i$ 处非线性，并且在岭回归中没有相近的表达式．计算 lasso 的解是一个二次规划问题，尽管我们在 3.4.4 节看到当 $\lambda$ 不同时计算解的整个路径存在与岭回归同样计算量的有效算法．由于该约束的本质，令 $t$ 充分小会造成一些参数恰恰等于 0．因此 lasso 完成一个温和的连续子集选择．如果所选的 $t$ 大于$t_0=\sum_1^p\vert\hat{\beta}_j\vert$（其中 $\hat{\beta}_j=\hat{\beta}_j^{ls}$，$\hat{\beta}_j^{ls}$ 为最小二乘估计），则 lasso 估计为 $\hat{\beta}_j$．另一方面，当 $t=t_0/2$，最小二乘系数平均收缩 $50\%$．然而，收缩的本质不是很显然，我们将在 3.4.4 节进一步研究．类似在变量子集选择中子集的大小，或者岭回归的惩罚参数，应该自适应地选择 $t$ 使预测误差期望值的估计最小化．</p>
<p>图 3.7 中，为了方便解释，我们已经画出 lasso 的预测误差估计关于标准化参数 $s=t/\sum^p_1\vert\hat{\beta}_j\vert$ 的曲线．通过 10 折交叉验证选择 $s\approx 0.36$；这使得 4 个系数为 0（表 3.3 的第 5 列）．最终模型有第二低的测试误差，比全最小二乘模型略低，但是测试误差估计的标准误差（表 3.3 的最后一行）相当大．</p>
<p>图 3.10 显示了当惩罚参数 $s=t/\sum_1^p\vert\hat{\beta}_j\vert$ 不同时的 lasso 系数．当 $s=1.0$ 时为最小二乘估计；当 $s\rightarrow 0$ 时下降为 0．该下降不总是严格单调的，尽管例子中确实是．在 $s=0.36$ 处画了垂直直线，该值通过交叉验证来选择．</p>
<p><img alt="" src="../../img/03/fig3.10.png" /></p>
<blockquote>
<p>图 3.10 当惩罚参数 $t$ 变化时的 lasso 系数曲线．图中画了系数关于 $s=t/\sum^p_1\vert\hat{\beta}_j\vert$ 的曲线．垂直直线画在 $s=0.36$ 处，该值通过交叉验证来选择．比较 65 页的图 3.8，lasso 曲线会达到 0，然而岭回归不会．曲线是分段线性的，所以只计算显示点处的值；详见 3.4.4 节．</p>
</blockquote>
<h2 id="lasso_1">讨论：子集的选择，岭回归，Lasso<a class="headerlink" href="#lasso_1" title="Permanent link">&para;</a></h2>
<p>这部分我们讨论并且比较至今为止有约束的线性回归模型的三种方法：子集选择、岭回归和 lasso．</p>
<p>在正交输入矩阵的情况下，三种过程都有显式解．每种方法对最小二乘估计 $\hat{\beta}_j$ 应用简单的变换，详见表 3.4．</p>
<p><img alt="" src="../../img/03/tab3.4.png" /></p>
<blockquote>
<p>表 3.4 在 $\mathbf{X}$ 为正规列情形下 $\beta_j$ 的估计值．$M$ 和 $\lambda$ 是通过对应的手段选择的常数；符号标记变量的符号（$\pm 1$），而且 $x_+$ 记 $x$ 的正数部分．下面的表格中，估计值由红色虚线来显示．灰色的 $45^{\circ}$ 直线作为参照显示了无约束的估计．</p>
</blockquote>
<p>岭回归做等比例的收缩．lasso 通过常数因子 $\lambda$ 变换每个系数，在 0 处截去．这也称作“软阈限”，而且用在 <a href="../../05-Basis-Expansions-and-Regularization/5.9-Wavelet-Smoothing/index.html">5.9 节</a>中基于小波光滑的内容中．最优子集选择删掉所有系数小于第 $M$ 个大系数的变量；这是“硬阈限”的一种形式．</p>
<p>回到非正交的情形，一些图象可以帮助了解它们之间的关系．当只有两个参数时图 3.11 描绘了 lasso（左）和岭回归（右）．残差平方和为椭圆形的等高线，以全最小二乘估计为中心．岭回归的约束区域为圆盘 $\beta_1^2+\beta_2^2\le t$，lasso 的约束区域为菱形$\vert\beta_1\vert+\vert\beta_2\vert\le t$．两种方式都寻找当椭圆等高线达到约束区域的第一个点．与圆盘不同，<strong>菱形 (diamond)</strong> 有角；如果解出现在角上，则有一个参数 $\beta_j$ 等于 0．当 $p &gt; 2$，菱形变成了 <strong>偏菱形 (rhomboid)</strong>，而且有许多角，平坦的边和面；对于参数估计有更多的可能为 0．</p>
<p><img alt="" src="../../img/03/fig3.11.png" /></p>
<blockquote>
<p>图 3.11 lasso (左)和岭回归（右）的估计图象．图中显示了误差的等高线和约束函数．实心蓝色区域分别为约束区域$\vert\beta_1\vert+\vert\beta_2\vert\le t$以及$\beta^2_1+\beta_2^2\le t^2$，红色椭圆为最小二乘误差函数的等高线．</p>
</blockquote>
<p>我们可以把岭回归和 lasso 一般化，并且可以看成是贝叶斯估计．考虑下面准则
<script type="math/tex; mode=display">
\tilde{\beta}=\underset{\beta}{\arg\min}\Big\{\sum\limits_{i=1}^N(y_i-\beta_0-\sum\limits_{j=1}^px_{ij}\beta_j)^2+\lambda\sum\limits_{j=1}^p\vert\beta_j\vert^q\Big\}\tag{3.53}\label{3.53}
</script>
</p>
<p>其中 $q\ge 0$．图 3.12 显示了两个输入情形下常数值 $\sum_j\vert\beta_j\vert^q$ 的等高线．</p>
<p><img alt="" src="../../img/03/fig3.12.png" /></p>
<blockquote>
<p>图 3.12 给定值 $q$ 下常数值 $\sum_j\vert\beta_j\vert^q$ 的等高线．</p>
</blockquote>
<p>将 $\vert\beta_j\vert^q$ 看成 $\beta_j$ 的先验概率密度的对数值，同样有参数先验分布的等高线．$q=0$ 对应变量子集选择，惩罚项是简单地统计非零参数的个数；$q=1$ 对应 lasso，$q=2$ 对应岭回归．注意到 $q\le 1$，先验在各方向上不是均匀的，而是更多地集中在坐标方向上．对应 $q=1$ 情形的先验分布是关于每个输入变量是的独立的二重指数分布（或者 Laplace 分布），概率密度为$(1/2\tau)exp(-\vert\beta\vert)/\tau$ 并且 $\tau=1/\lambda$．$q=1$ 的情形（lasso）是使得约束区域为凸的最小 $q$ 值；非凸约束区域使得优化问题很困难．</p>
<p>从这点看，lasso、岭回归和最优子集选择是有着不同先验分布的贝叶斯估计．然而，注意到它们取自后验分布的众数，即最大化后验分布．在贝叶斯估计中使用后验分布的均值更加常见．岭回归同样是后验分布的均值，但是 lasso 和最优子集选择不是．</p>
<p>再一次观察准则 \eqref{3.53}，我们可能尝试除 0，1，2 外的其它 $q$ 值．尽管有人可能从数据中估计 $q$，我们的经验表明引入额外的方差不值得．$q\in (1,2)$ 表明在 lasso 和岭回归之间进行权衡．当 $ q &gt; 1$ 时尽管 $\vert\beta_j\vert^q$ 在 0 处可导，但是并没有lasso（$q=1$）的令系数恰巧为零的性质．部分由于这个原因并且考虑计算易处理，Zou and Hastie (2005)<sup id="fnref:4"><a class="footnote-ref" href="#fn:4">4</a></sup> 引入弹性惩罚</p>
<p>
<script type="math/tex; mode=display">
\lambda \sum\limits_{j=1}^p(\alpha\beta_j^2+(1-\alpha)\vert\beta_j\vert)\tag{3.54}
</script>
</p>
<p>这是一种岭回归和 lasso之间的平衡．图 3.13 比较了 $q=1.2$ 下的 $L_q$ 惩罚以及 $\alpha=0.2$ 的弹性网惩罚；很难从肉眼来观察出差异．弹性网像 lasso 一样选择变量，同时像岭回归一样收缩相关变量的系数．同时考虑了 $L_q$ 惩罚的计算优势．我们将在 <a href="../../18-High-Dimensional-Problems/18.4-Linear-Classifiers-with-L1-Regularization/index.html">18.4节</a>介绍弹性网惩罚．</p>
<p><img alt="" src="../../img/03/fig3.13.png" /></p>
<blockquote>
<p>图3.13 $q=1.2$ 时 $\sum_j\vert\beta_j\vert^q$ 为常数值的轮廓线（左图）以及 $\alpha=0.2$ 时弹性网惩罚 $\sum_j(\alpha\beta_j^2+(1-\alpha)\vert\beta_j\vert)$ 为常数值的轮廓线（右图）．尽管看起来很相似，弹性网有尖角（不可导），而 $q=1.2$ 的惩罚不会有尖角．</p>
</blockquote>
<h2 id="_2">最小角回归<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p><strong>最小角回归 (LAR)</strong> 是相对较新的方法 (Efron et al., 2004<sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup>)，而且可以看成是一种向前逐步回归（3.3.2 节）的“民主 (democratic)”版本．正如我们将看到的，LAR 与 lasso 联系紧密，并且事实上提供了如图 3.10 所示的计算整个 lasso 路径的非常有效的算法．</p>
<div class="admonition note">
<p class="admonition-title">weiya 注：</p>
<p>在 Efron 的论文中，最小角回归缩写为 LARS，我们这里仍以 ESL 书上的缩写为准——LAR</p>
</div>
<p>向前逐步回归逐步建立模型，每次添加一个变量．每一步，它选出最好的变量加入活跃集，然后更新最小二乘来加入所有的活跃变量．</p>
<p>最小角回归采用类似的策略，但是仅仅加入一个变量应有的程度．第一步它确定与响应变量最相关的变量．不是完全的拟合该变量，LAR 使得该变量的系数向最小二乘值连续变化（使得它与进化的残差之间的相关系数绝对值降低）．只要其他变量与残差的相关性与该变量和残差的相关性相等，则该过程暂停．第二个变量加入活跃集，然后它们的系数一起以保持相关性相等并降低的方式变化．这个过程一直继续直到所有的变量都在模型中，然后在全最小二乘拟合处停止．算法 3.2 给出了详细过程．第 5 步的终止条件需要一些解释．如果 $p &gt;N-1$，LAR 算法经过 $N-1$ 步达到 0 残差解（$-1$ 是因为我们已经对数据进行了中心化）</p>
<p><img alt="" src="../../img/03/Alg3.2.png" /></p>
<hr />
<p><strong>算法 3.2</strong> 最小角回归</p>
<hr />
<ol>
<li>对预测变量进行标准化处理得到零均值和单位范数．以残差向量 $\mathbf{r=y-\bar{y}},\beta_1,\ldots,\beta_p=0$ 开始．</li>
<li>找出与 $\mathbf{r}$ 最相关的预测变量 $\mathbf x_j$</li>
<li>从 0 开始移动 $\beta_j$ 一直到最小二乘系数 $\langle\mathbf x_j, \mathbf r\rangle$，直到存在其它的预测变量 $\mathbf x_k$ 使得其与当前残差的相关性等于 $\mathbf x_j$ 与当前残差的相关性．</li>
<li>在由当前残差在 $(\mathbf x_j,\mathbf x_k)$ 上的联合最小二乘系数方向上移动 $\beta_j$ 和 $\beta_k$，直到存在其它的预测变量 $x_l$ 与当前残差的相关性和当前残差与 $(\mathbf x_j,\mathbf x_k)$ 的相关性相等．</li>
<li>按这种方式继续直到所有的 $p$ 个预测变量加入到模型中．经过 $\min(N-1, p)$ 步，我们达到了全最小二乘的解．</li>
</ol>
<hr />
<div class="admonition tip">
<p class="admonition-title">weiya 注：LAR 示意图</p>
<p>结合原论文的示意图能帮助理解最小角回归的逻辑．</p>
<p><img alt="" src="../../img/03/lars.png" /></p>
</div>
<p>假设 $\cal A_k$ 是第 $k$ 步开始时的变量活跃集，$\beta_{\cal A_k}$ 是这一步中变量的系数向量；其中有 $k-1$ 个非零值，刚刚进入的变量系数值为 0．如果当前残差为 $\mathbf r_k=\mathbf y-\mathbf X_{\cal A_k}\beta_{\cal A_k}$，则当前步的方向为</p>
<p>
<script type="math/tex; mode=display">
\delta_k=(\mathbf X^T_{ \cal A_k}\mathbf X_{\cal A_k})^{-1}\mathbf X^T_{\cal A_k}\mathbf r_k \tag{3.55}
</script>
</p>
<p>然后系数迭代为 $\beta_{\cal A_k} (\alpha) = \beta_{\cal A_k} + \alpha · \delta_k$．<a href="https://github.com/szcf-weiya/ESL-CN/issues/100">练习 3.23</a> 证明这种方式下选择的方向满足断言：<strong>保持（各个预测变量与残差间的）相关系数相等和递减（tied and decreasing）</strong>．</p>
<div class="admonition info">
<p class="admonition-title">weiya 注：Ex. 3.23</p>
<p>已解决，具体证明过程参见<a href="https://github.com/szcf-weiya/ESL-CN/issues/100">Issue 100: Ex. 3.23</a>．起初翻译时，对 tied 的理解不够，通过求解该练习题，认为 tied 意思其实就是<strong>各个预测变量与残差之间的相关系数保持相等</strong>．</p>
</div>
<p>如果该步的开始拟合向量为 $\hat{\mathbf f}_k$，则迭代为 $\hat{\mathbf f}_k(\alpha)=\mathbf f_k+\alpha\cdot\mathbf u_k$，其中 $\mathbf u_k=\mathbf X_{\cal A_k}\delta_k$ 是新的拟合方向．“最小角”由该过程的几何解释得到；$\mathbf u_k$ 使得活跃集 ${\cal A}_k $中预测变量间的角度最小（<a href="https://github.com/szcf-weiya/ESL-CN/issues/101">练习 3.24</a>）．</p>
<div class="admonition info">
<p class="admonition-title">weiya 注：Ex. 3.24</p>
<p>已解决，详见 <a href="https://github.com/szcf-weiya/ESL-CN/issues/101">Issue 101: Ex. 3.24</a>，欢迎交流讨论．</p>
</div>
<p>图 3.14 使用模拟数据显示了相关系数的绝对值下降以及每一步 LAR 算法中变量进入的顺序．</p>
<p><img alt="" src="../../img/03/fig3.14.png" /></p>
<blockquote>
<p>图 3.14：通过 6 个预测变量的拟合数据集，每一步 LAR 过程中的相关性绝对值的变化．图象上方的标签表示在每一步哪些变量加进了活跃集．步长是用单位 $L_1$ 弧长来测量的．</p>
</blockquote>
<p><img alt="" src="../../img/03/fig3.15.png" /></p>
<p>由构造知 LAR 的系数以一种分段线性的方式进行改变．图 3.15（左图）显示了 LAR 系数曲线作为 $L_1$ 弧长的函数曲线．</p>
<div class="admonition note">
<p class="admonition-title">weiya 注：原书脚注</p>
<p>$L_1$ arc length：可导曲线 $\beta(s), s \in [0,S]$ 的 $L_1$ 弧长为 $TV(\beta,S)=\int_0^S\Vert\dot{\beta}(s)\Vert_1ds$，其中 $\dot{\beta}(s)=\partial\beta(s)/\partial s$．对于分段 LAR 函数曲线，这相当于从这一步到下一步系数的 $L_1$ 范数变化之和．</p>
</div>
<blockquote>
<p>图 3.15：左图显示了 LAR 系数作为 $L_1$ 长度的函数在模拟数据上的图象．右图显示了 Lasso 的图象．它们大概在 $L_1$ 弧长为 18 之前（深蓝色的系数曲线通过 0）都是完全相同的.</p>
</blockquote>
<p>注意到我们不需要走很小的步以及重新检查步骤 3 的相关系数；应用预测变量的协方差和算法的分段线性性质，我们可以在每一步开始计算出确切的步长（<a href="https://github.com/szcf-weiya/ESL-CN/issues/98">练习 3.25</a>）．</p>
<div class="admonition info">
<p class="admonition-title">weiya 注：Ex. 3.25</p>
<p>已解决，详见 <a href="https://github.com/szcf-weiya/ESL-CN/issues/98">Issue 98: Ex. 3.25</a>，欢迎讨论交流！</p>
</div>
<p>图 3.15 的右图展示了对同样数据的 lasso 系数曲线．几乎与左图相同，当绿色曲线通过 0 时首次出现不同．对于前列腺癌数据，LAR 系数曲线显示与图 3.10 的 lasso 曲线相同，该曲线从不经过 0．这些观测值促使对 LAR 算法进行简单修改，给出了整个 lasso 路径，它同样也是分段线性的．</p>
<p><img alt="" src="../../img/03/Alg3.2a.png" /></p>
<hr />
<p><strong>算法 3.2a</strong> 最小角回归：Lasso修正</p>
<hr />
<p>4a. 如果一个非零的系数达到0，则从变量的活跃集中删除该变量并且重新计算当前的联合最小二乘方向．</p>
<hr />
<p>LAR(lasso) 算法是非常有效的，需要用 $p$ 个预测变量的单最小二乘拟合的相同步骤进行计算．最小角回归总是需要 $p$ 步达到全最小二乘估计．lasso 路径可能超过 $p$ 步，尽管这两者经常是非常相似的．经过 lasso 修正的 3.2a 的算法 3.2 是计算任何一个lasso 问题的有效方式，特别是当 $p &gt; &gt;N$．Osborne et al. (2000a)<sup id="fnref:5"><a class="footnote-ref" href="#fn:5">5</a></sup> 也发现了计算 lasso 的分段线性的路径，他们称之为<strong>同伦 (homotopy)</strong> 算法．</p>
<p>我们已经给出一个为什么这些过程很相似的启发式的论据．尽管 LAR 算法是用相关性来叙述的，但如果输入特征是标准化的，它与内积是等价的并且用内积更简单．假设 $\cal A$ 是算法中某些步的变量活跃集，它们与当前残差 $\mathbf y -\mathbf X\beta$ 的内积的绝对值是结合在一起的．我们可以表达成</p>
<p>
<script type="math/tex; mode=display">
\mathbf x_j^T(\mathbf y-\mathbf X\beta)=\gamma\cdot s_j,\forall j\in {\cal A} \tag{3.56}\label{3.56}
</script>
</p>
<p>其中 $s_j\in\{-1,1\}$ 表示内积的符号，$\gamma$ 是普通的数值．并且 $\vert \mathbf x_k^T(\mathbf y-\mathbf X\beta)\vert\le \gamma\; \forall k\notin \cal A$．现在我们考虑 \eqref{3.52} 的 lasso 准则，我们可以写成向量形式</p>
<p>
<script type="math/tex; mode=display">
R(\beta)=\frac{1}{2}\Vert\mathbf y-\mathbf X\beta\Vert_2^2+\lambda\Vert\beta\Vert_1\tag{3.57}
</script>
</p>
<p>令 $\cal B$ 为在给定 $\lambda$ 值下解中的变量的活跃集．对于这些变量 $R(\beta)$ 是可导的，并且 <strong>平稳条件 (stationary condition)</strong> 为</p>
<p>
<script type="math/tex; mode=display">
\mathbf x_j^T(\mathbf y-\mathbf X\beta)=\lambda\cdot \sign(\beta_j),\forall j\in {\cal B}\tag{3.58}\label{3.58}
</script>
</p>
<p>比较 \eqref{3.58} 和 \eqref{3.56}，我们看到只有当 $\beta_j$ 的符号与内积的符号相同时，这两个等式才相同．这也就是为什么 LAR 算法和 lasso 当一个活跃系数经过零开始出现不同；对于不满足条件 \eqref{3.58} 的变量，会被踢出活跃集 $\cal B$．<a href="https://github.com/szcf-weiya/ESL-CN/issues/100">练习 3.23</a> 证明了这些等式表明随$\lambda$ 减小的分段线性系数曲线．对于不活跃的变量的平稳条件要求</p>
<p>
<script type="math/tex; mode=display">
\vert\mathbf x_k^T(\mathbf y-\mathbf X\beta)\vert\le\lambda,\forall k\notin{\cal B}\tag{3.59}
</script>
</p>
<p>这与 LAR 算法一致．</p>
<p><img alt="" src="../../img/03/fig3.16.png" /></p>
<blockquote>
<p>图 3.16：LAR、lasso、向前逐步、向前逐渐（FS）和增长向前逐渐（$FS_0$）回归之间的比较．设定与图3.6相同，除了这里$N=100$而不是300.这里较慢的$FS$回归最终表现得比向前逐步好．LAR和lasso表现得和FS、$FS_0$相似．因为这些过程采取不同的步数（根据模拟复制和方法），我们画出最小二乘拟合的MSE关于整体$L_1$弧长的片段的函数．</p>
</blockquote>
<p>图 3.16 将 LAR 和 lasso 与向前逐步（forward stepwise）和向前逐渐（forward stagewise）回归进行比较．设定与图 3.6 是相同的，除了这里的 $N=100$ 而不是 $300$，所以这个问题更加困难．我们可以看到增长性更快的向前逐步很快地过拟合（10 个变量加入模型中之前是很好的），最终比增长性较慢的向前逐渐回归表现得更差．LAR 和 lasso 的行为与向前逐渐回归相似．增长的向前逐渐回归与 LAR 和 lasso 类似，并且将在 <a href="../../03-Linear-Methods-for-Regression/3.8-More-on-the-Lasso-and-Related-Path-Algorithms/index.html">3.8.1 节</a>中描述．</p>
<h3 id="lar-lasso">LAR 和 Lasso 自由度公式<a class="headerlink" href="#lar-lasso" title="Permanent link">&para;</a></h3>
<p>假设我们通过最小角回归过程拟合了线性模型，在某步 $k &lt; p$ 停止，或者等价地用 lasso 的界 $t$ 得到约束情况下的全最小二乘拟合．我们需要多少参数，或者自由度？</p>
<p>首先考虑采用 $k$ 个特征的子集的线性回归．如果这个子集是没有通过训练数据而事先确定好的，然后在该拟合模型中的自由度定义为$k$．当然，在经典统计学中，线性独立参数的个数也就是自由度．另外地，假设我们用一个最优子集选择确定了最优的 $k$ 个预测变量．于是结果模型中有 $k$ 个参数，但在某种意义上我们用了大于 $k$ 个的自由度．</p>
<p>我们需要一个对于自适应拟合模型的有效自由度的一般定义．我们定义拟合向量 $\hat{\mathbf y}=(\hat y_1,\hat y_2,\ldots,\hat y_N)$ 的自由度为
<script type="math/tex; mode=display">
\df(\hat{\mathbf y})=\frac{1}{\sigma^2}\sum\limits_{i=1}^N\Cov(\hat y_i,y_i)\tag{3.60}\label{3.60}
</script>
这里 $\Cov(\hat y_i,y_i)$ 指的是预测值 $\hat y_i$ 和其对应的输出向量 $y_i$ 之间的协方差．直观上看有意义：当拟合数据越困难，协方差会越大，从而 $\df(\hat{\mathbf y})$ 越大．表达式 \eqref{3.60} 是一个有用的自由度的概念，可以应用到任何模型的预测向量 $\hat{\mathbf y}$．其中包括那些对训练数据自适应拟合的模型．这个定义将在 <a href="../../07-Model-Assessment-and-Selection/7.6-The-Effective-Number-of-Parameters/index.html">7.4-7.6 节</a> 中进一步讨论．</p>
<p>现在对于有 $k$ 个固定预测变量的线性回归模型，可以简单地证明 $\df(\hat{\mathbf y})=k$．同样地，对于岭回归，这一定义导出表达式（3.50）的 <strong>闭型解 (closed-form)</strong>：$\df(\hat{\mathbf{y}})=\tr(\mathbf S_\lambda)$．</p>
<p>在这些情况下，\eqref{3.60} 可以很简单地进行赋值因为 $\hat{\mathbf{y}}=\mathbf{H}_\lambda\mathbf y$ 关于 $\mathbf y$ 是线性的．如果我们考虑在大小为 $k$ 的最优子集选择中的定义 \eqref{3.60}，似乎显然有 $\df(\hat{\mathbf y})$ 会大于 $k$，并且可以通过运用模拟的方法直接地估计 $\Cov(\hat y_i,y_i)/\sigma^2$ 来验证．然而估计最优子集选择的 $\df(\hat{\mathbf y})$ 没有闭型解．</p>
<p>对于 LAR 和 lasso，会发生很奇怪的事情．这些技巧的自适应方式比最优集选择更加光滑，因此估计自由度会更加地难以驾驭．特别地，可以证明经过 $k$ 步 LAR 过程，拟合向量的有效自由度恰巧是 $k$．对于 lasso，（改进的）LAR 过程经常需要多余 $k$ 的步骤，因为可以删去预测变量．因此，定义有点不一样；对于 lasso，在任一小步 $\df(\hat{\mathbf y})$ 近似等于模型中预测变量的个数．然而这种近似在 lasso 路径中的任何地方都表现得很好，但是对于每个 $k$，它在包含 $k$ 个预测变量的序列中最后一个模型表现得最好．关于 lasso 自由度详细的研究或许可以在 Zou et al. (2007)<sup id="fnref:6"><a class="footnote-ref" href="#fn:6">6</a></sup> 中找到．</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Hoerl, A. E. and Kennard, R. (1970). Ridge regression: biased estimation for nonorthogonal problems, Technometrics 12: 55–67.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>Chen, S. S., Donoho, D. and Saunders, M. (1998). Atomic decomposition by basis pursuit, SIAM Journal on Scientific Computing 20(1): 33–61.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p>Efron, B., Hastie, T., Johnstone, I. and Tibshirani, R. (2004). Least angle regression (with discussion), Annals of Statistics 32(2): 407–499.&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:4">
<p>Zou, H. and Hastie, T. (2005). Regularization and variable selection via the elastic net, Journal of the Royal Statistical Society Series B. 67(2): 301–320.&#160;<a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:5">
<p>Osborne, M., Presnell, B. and Turlach, B. (2000a). A new approach to variable selection in least squares problems, IMA Journal of Numerical Analysis 20: 389–404.&#160;<a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
<li id="fn:6">
<p>Zou, H., Hastie, T. and Tibshirani, R. (2007). On the degrees of freedom of the lasso, Annals of Statistics 35(5): 2173–2192.&#160;<a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text">&#8617;</a></p>
</li>
</ol>
</div>
                
                  
                
              
              
                
                  <h2 id="__comments">💬 讨论区</h2>
                  <script src="https://giscus.app/client.js"
        data-repo="szcf-weiya/ESL-CN"
        data-repo-id="MDEwOlJlcG9zaXRvcnk2OTYyNTgzOA=="
        data-category="评论区"
        data-category-id="DIC_kwDOBCZn7s4ChHU6"
        data-mapping="pathname"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>
</script>


<div id="disqus_thread"></div>
<script>
  if (window.location.hostname !== "localhost" && window.location.hostname !== "127.0.0.1") {
    var disqus_config = function () {
      this.page.url = "https://esl.hohoweiya.xyz/03-Linear-Methods-for-Regression/3.4-Shrinkage-Methods/index.html";
      this.page.identifier =
        "/03-Linear-Methods-for-Regression/3.4-Shrinkage-Methods/index.html";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//esl-hohoweiya-xyz.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  } else {
    console.log("Disqus is disabled on localhost.");
  }
</script>


                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../3.3-Subset-Selection/index.html" title="3.3 子集的选择" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                3.3 子集的选择
              </span>
            </div>
          </a>
        
        
          <a href="../3.5-Methods-Using-Derived-Input-Directions/index.html" title="3.5 运用派生输入方向的方法" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                3.5 运用派生输入方向的方法
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016-2025 weiya
          </div>
        
        <!--
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
        -->
        Last Build Date UTC : 2025-03-07 18:08:14
      </div>
      
        
  <div class="md-footer-social">
    
    <!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">--> <!--<link rel="stylesheet" href="../../css/mini-awesome/font-awesome.css">-->    
      <a href="https://github.com/szcf-weiya" class="md-footer-social__link fa fa-github"></a>
    
      <a href="https://tech.hohoweiya.xyz" class="md-footer-social__link fa fa-code"></a>
    
      <a href="https://hohoweiya.xyz" class="md-footer-social__link fa fa-home"></a>
    
      <a href="https://stats.hohoweiya.xyz" class="md-footer-social__link fa fa-rss"></a>
    
      <a href="https://www.linkedin.com/in/szcfweiya/" class="md-footer-social__link fa fa-linkedin"></a>
    
      <a href="mailto:szcfweiya@gmail.com" class="md-footer-social__link fa fa-envelope"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
          <!---->
    <script src="../../assets/javascripts/application.43ad2ac2.js"></script>
    <!--
      
    -->
	    <script>app.initialize({version:"0.17.2",url:{base:"../.."}})</script>
	          <!---->

    <script>var base_url = '../..';</script>
    <!--
      
    -->
    <script src="../../js/baiduzhanzhang.js"></script>
    
    
      
        <script>!function(e,a,t,n,o,c,i){e.GoogleAnalyticsObject=o,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),i=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",i.parentNode.insertBefore(c,i)}(window,document,"script",0,"ga"),ga("create","UA-85046550-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");if(Array.prototype.map.call(links,function(e){e.host!=document.location.host&&e.addEventListener("click",function(){var a=e.getAttribute("data-md-action")||"follow";ga("send","event","outbound",a,e.href)})}),document.forms.search){var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}</script>
      
    
    <!--adjust disqus recommendation width (possibly occupied by ads)-->
    <script>
// 确保在 DOM 完全加载后执行
document.addEventListener('DOMContentLoaded', function() {
    // 定义修复宽度的函数
    function fixDisqusWidth() {
        const iframe = document.querySelector('#disqus_recommendations iframe');
        if (iframe) {
            iframe.style.cssText += 'width: 100% !important; max-width: 100% !important;';
        }
    }

    // 初次尝试修复
    fixDisqusWidth();

    // 监听 Disqus 容器的动态加载
    const observer = new MutationObserver(function(mutations) {
        fixDisqusWidth();
    });

    // 获取 Disqus 容器
    const targetNode = document.getElementById('disqus_recommendations');
    if (targetNode) {
        // 如果容器已存在，直接监听
        observer.observe(targetNode, { childList: true, subtree: true });
    } else {
        // 如果容器未加载，监听整个文档直到其出现
        const docObserver = new MutationObserver(function(mutations) {
            const lateTarget = document.getElementById('disqus_recommendations');
            if (lateTarget) {
                observer.observe(lateTarget, { childList: true, subtree: true });
                docObserver.disconnect();
            }
        });
        docObserver.observe(document.body, { childList: true, subtree: true });
    }
});
    </script>
  </body>
</html>