# 2.2 变量类型和术语

原文     | [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf#page=28)
      ---|---
翻译     | szcf-weiya
 发布 | 2016-09-30 
更新 | 2018-08-21
状态 | Done

这些例子中的输出变量本质都不相同．在预测葡萄糖的例子中，输出变量是 **定量 (quantitative)** 的度量，有些度量大于其他的，而且测量结果在数值上相近也意味着结果本质上相近．著名的 R.A.Fisher 分辨鸢尾花种类例子中，输出变量（鸢尾花的种类）是 **定性的 (qualitative)** 而且假设取值为有限集合 ${\cal G}=\\{Virginica,Setosa,Versicolor\\}$．在手写数字的例子中，输出变量的取值是 $10$ 个不同数字之一：${\cal G}=\\{0,1,...,9\\}$．在这些例子中分类没有明显的顺序，而且事实上经常用描述性标签而不是数字来代替这些分类．定性变量也被称为 **类别型 (categories)** 或者 **离散 (discrete)** 型变量，也被称作 **因子 (factors)**．

对于两种类型的输出变量，考虑使用输入变量去预测输出变量是有意义的．给定今天和昨天特定的大气测量结果，我们想要预测明天的臭氧层．给定手写数字的数字化图片中像素的灰度值，我们想要预测该图片是属于哪一个类．

输出类型的差别导致对预测的命名规定：当我们预测定量的输出时被称为 **回归 (regression)**，当我们预测定性的输出时被称为 **分类(classification)**．我们将会看到这两个任务有很多的共同点，特别地，两者都可以看成是函数逼近．

输入变量也有各种各样的测量类型；我们可以有定性的输入变量和定量的输入变量两者中的一些变量．这些也导致了预测中方法类型的不同：一些方法更自然地定义为定量的输入变量，一些方法更自然地定义为定性的输入变量，还有一些是两者都可以的．

第三种变量类型是 **有序分类 (ordered categorical)**，如 **小(small)**、**中 (medium)** 和 **大 (large)**，在这些值之间存在顺序，但是没有合适的度量概念（中与小之间的差异不必和大与中间的差异相等）．这将在[第四章](../04-Linear-Methods-for-Classification/4.1-Introduction/index.html)中讨论．

定性的变量常用数字编码来表示．最简单的情形是只有两个分类，比如说“成功”与“失败”，“生存”与“死亡”．这些经常用一位二进制数来表示，比如 $0$ 或 $1$，或者用 $-1$ 和 $1$ 来表示．因为一些显然的原因，这些数字编码有时被称作 **指标 (targets)**．当存在超过两个的类别，存在其他可行的选择．最有用并且最普遍使用的编码是 **虚拟变量(dummy variables)**．这里有 $K$ 个水平的定性变量被一个 $K$ 位的二进制变量表示，每次只有一个在开启状态．尽管更简洁的编码模式也是可能的，但虚拟变量在因子的层次中是对称的．

我们将经常把输入变量用符号 $X$ 来表示．如果 $X$ 是一个向量，则它的组成部分可以用下标 $X_j$ 来取出．定量的输出变量用 $Y$ 来表示，对于定性的输出变量采用 $G$ 来表示（group 的意思）．当指一般的变量，我们使用大写字母 $X,Y,G$ 来表示，对于观测值我们用小写字母来表示；因此 $X$ 的第 $i$ 个观测值记作 $x_i$ （其中，$x_i$ 要么是标量要么是向量）矩阵经常用粗体的大写字母来表示；举个例子，$N$ 个 $p$ 维输入向量 $x_i,i=1,\cdots,N$ 可以表示成 $N\times p$ 的矩阵 $\mathbf{X}$ ．一般地，向量不是粗体，除非它们有 $N$ 个组成成分；这个约定区分了包含变量 $X_j$ 的所有观测值的 $N$ 维向量 $\mathbf{x}_j$ 和第 $i$ 个观测值的 $p$ 维向量 $x_i$ ．因为所有的向量都假定为列向量， $\mathbf{X}$ 的第 $i$ 行是 $x_i$ 的转置 $x_i^T$ ．

现在我们可以不严谨地把学习叙述成如下：给定输入向量 $X$，对输出 $Y$ 做出一个很好的估计，记为 $\hat{Y}$ ．如果 $Y$ 取值为 $\mathbf{R}$，则 $\hat{Y}$ 取值也是 $\mathbf{R}$ ；同样地，对于类别型输出，$\hat{G}$ 取值为对应 $G$ 取值的集合 $\cal{G}$．

对于只有两种类别的 $G$，一种方式是把二进制编码记为 $Y$，然后把它看成是定量的输出变量．预测值 $\hat{Y}$ 一般落在 $[0,1]$ 之间，而且我们可以根据 $\hat{y} > 0.5$ 来赋值给 $\hat{G}$ ．这种方式可以一般化为有 $K$ 个水平的定性的输出变量．

我们需要数据去构建预测规则，经常是大量的数据．因此我们假设有一系列可用的测量值 $(x_i,y_i)$ 或 $(x_i,g_i),i=1,\cdots,N$ ，这也称之为 **训练数据 (training data)**，将利用这些训练数据去构建我们的预测规则．
